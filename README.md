# CS/ME 598 SML, Fall 2023: Scientific Machine Learning

## Course info:
* Mondays and Wednesdays, 11-12:15
* Location: DCL 1265
* Instructors:
  * Prof. Luke Olson, http://lukeo.cs.illinois.edu/
  * Prof. Matt West, https://lagrange.mechse.illinois.edu/
  * <span style="color:red">Are you looking to join the class?</span>   Unfortunately the class is full!  Auditing and sitting in on the class cannot be accommodated.  Sorry! (In future semesters we are hoping to expand the offering.)

## Course links:
* Public access repo (here): https://github.com/lukeolson-group/598sml-f23-syllabus
* Private class repo: https://github.com/lukeolson-group/598sml-f23-hw
* Slack: https://598sml-f23.slack.com/

## Course blurb

Familiarity with introductory numerical methods (e.g., CS 357 or TAM 470) and
is a prerequisite, preferably with some experience with numerical PDEs. The
course will cover the theory and practice of Scientific Machine Learning
(SciML), which leverages machine learning tools for scientific computing.
Topics include learning-based methods for differential equations, neural ODEs
and PDEs, physics-informed networks and model discovery, interpretable and
explainable learning, differentiable and probabilistic programming for
scientific computing, and uncertainty quantification via learning. Efficient
parallel implementation of algorithms on scalable computing architectures will
be emphasized.

## What to expect

The course requires some background in numerical methods (e.g. CS357, CS450, or
TAM 470 type courses), but no prior knowledge of machine learning or experience
with neural networks.  As such, the course will build the necessary tools through
the semester, with a focus on scientific applications.

The course is project based, particularly the last half.  You will use `git`,
`pytorch`, and `latex` to develop various examples and steps toward your final
project.

Assignments will be submitted on the [internal GitHub repository](https://github.com/lukeolson-group/598sml-f23-hw)

## On COVID and the class

While face coverings are not required in classrooms (current as of 08/23) we
fully support your decision to wear one if you wish.

If you test positive for COVID, then you should not attend class.

If you have any cold-like symptoms or do not feel well, then you should not
attend class, regardless of testing negative or positive for COVID.

In either case, your missed attendance due to illness will not impact
your grade in the course and we will work with you keep you up-to-date
on the material.

## Schedule

- `week01 (0821)`
  - Topic: What is Sci ML? And what is this course?
  - Topic: Overview of tools
- `week02 (0828)`
  - Topic: All about derivatives
  - Topic: Approximating functions
  - PINNs
- `week04 (0904)` (no class 0904)
   - Topic: survey of networks, what to use when and where
   - Topic: optimizers
   - Themes: hierarchy, invariance (CNNs are translationally invariant, e.g.)
- `week05 (0911)`
  - M: Selecting a project
  - W: xyz
- `week06 (0918)`
  - M: CPINNS
  - W: XPINNS and Domain Decomposition
- `week07 (0925)`
  - M: Project workflow, steps
  - W: Domain decomposition
  - W: Data workflows
- `week08 (1002)`
  - M: Elliptic PDEs
  - M: project goals, a list
  - W: Domain decomposition, HAL
- `week09 (1009)`
  - M: Project setup
  - W: Neural ODEs
- `week10 (1016)`
  - M: Domain decomposition and elliptic problems
  - M: Setting up the simulation
  - W: PyTorch on HAL
  - W: Neural ODEs
- `week11 (1023)`
  - M: Present training results
  - W: Neural Operators
- `week12 (1030)`
  - M: Project peer feedback
  - W: Graph Neural Networks
- `week13 (1106)`
  - M: Training results
  - W: Specialized talk
- `week14 (1113)`
  - M: Preliminary results, pretty picture
  - W: Neural Operators, DeepONets, and Gaussian Processes
- `week15 (1120)` ~~Thanksgiving~~
- `week16 (1127)` tbd
- `week17 (1204)` tbd
- `week17 (1211)` tbd

## Grading

Final course scores will be computed as 40% weekly Homeworks and 60% Final Project.

Grades will use the standard 10-point scale, so 90-100 is A-/A/A+, 80-90 is B-/B/B+, etc.
